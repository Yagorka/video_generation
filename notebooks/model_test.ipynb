{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mc_api_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import BOT_TOKEN, login, password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = mc_api_utils.autorization(login, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://mc.dev.rand.agency/page/45364153'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code, pages = mc_api_utils.get_my_pages(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code, biography = mc_api_utils.get_biography(url, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_num = 0\n",
    "for i in biography:\n",
    "    try:\n",
    "        images_num+=len(biography[i]['images'])\n",
    "    except Exception as ex:\n",
    "        pass\n",
    "images_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code, img = mc_api_utils.load_photo('https://src.mc.dev.rand.agency/storage/app/public/11017/1732697462.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discript image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModelForVision2Seq, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "    quantization_config=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "import torch\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\")\n",
    "\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers.image_utils import load_image\n",
    "\n",
    "\n",
    "# Load images\n",
    "image1 = img.copy()\n",
    "\n",
    "# Create input messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe the image?\"} #Please write a good short script that is well suited for creating an animation of this picture?\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=prompt, images=[image1], return_tensors=\"pt\")\n",
    "inputs = inputs.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate outputs\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=77)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "\n",
    "print(generated_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = generated_texts[0].split('Assistant:')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import (\n",
    "    EulerDiscreteScheduler,\n",
    "    MotionAdapter,\n",
    "    PIAPipeline,\n",
    ")\n",
    "from diffusers.utils import export_to_gif, load_image\n",
    "\n",
    "adapter = MotionAdapter.from_pretrained(\"openmmlab/PIA-condition-adapter\")\n",
    "pipe = PIAPipeline.from_pretrained(\"SG161222/Realistic_Vision_V6.0_B1_noVAE\", motion_adapter=adapter, torch_dtype=torch.float16)\n",
    "\n",
    "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_model_cpu_offload()\n",
    "pipe.enable_vae_slicing()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img.copy().resize((512, 512))\n",
    "# prompt = \"A car realystic driving\"\n",
    "prompt = \"The man is holding a helmet in his left hand and raising his right arm.\"\n",
    "negative_prompt = \"wrong white balance, dark, sketches,worst quality,low quality\"\n",
    "\n",
    "generator = torch.Generator(\"cpu\").manual_seed(0)\n",
    "output = pipe(image=image, prompt=prompt, generator=generator)\n",
    "frames = output.frames[0]\n",
    "export_to_gif(frames, \"pia-animationm.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelscopeT2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableVideoDiffusionPipeline\n",
    "from diffusers.utils import load_image, export_to_video\n",
    "\n",
    "pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-video-diffusion-img2vid\", torch_dtype=torch.float16, variant=\"fp16\"\n",
    ")\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "image = img.copy()\n",
    "\n",
    "generator = torch.manual_seed(42)\n",
    "frames = pipe(image, decode_chunk_size=8, generator=generator, num_frames=25).frames[0]\n",
    "export_to_video(frames, \"generatedm.mp4\", fps=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I2VGen-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import I2VGenXLPipeline\n",
    "from diffusers.utils import export_to_gif, load_image\n",
    "\n",
    "pipe = I2VGenXLPipeline.from_pretrained(\"ali-vilab/i2vgen-xl\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_url = \"https://huggingface.co/datasets/diffusers/docs-images/resolve/main/i2vgen_xl_images/img_0009.png\"\n",
    "image = img.copy()\n",
    "\n",
    "prompt = prompt #\"The man is holding a helmet in his left hand and raising his right arm.\"\n",
    "negative_prompt = \"Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms\"\n",
    "generator = torch.manual_seed(8888)\n",
    "frames = pipe(\n",
    "    prompt=prompt,\n",
    "    image=image,\n",
    "    num_inference_steps=50,\n",
    "    negative_prompt=negative_prompt,\n",
    "    guidance_scale=9.0,\n",
    "    generator=generator\n",
    ").frames[0]\n",
    "export_to_gif(frames, \"i2vm.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.utils import load_image, export_to_video\n",
    "export_to_video(frames, \"generatedm.mp4\", fps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_gif(image, output_gif_path: str = None, fps: int = 10) -> str:\n",
    "    if output_gif_path is None:\n",
    "        output_gif_path = tempfile.NamedTemporaryFile(suffix=\".gif\").name\n",
    "\n",
    "    image[0].save(\n",
    "        output_gif_path,\n",
    "        save_all=True,\n",
    "        append_images=image[1:],\n",
    "        optimize=False,\n",
    "        duration=1000 // fps,\n",
    "        loop=0,\n",
    "    )\n",
    "    return output_gif_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif = export_to_gif(frames, \"generatedm.gif\", fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_gif(frames, \"i2vm.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videodims = frames[0].size\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "FPS = 30\n",
    "video = cv2.VideoWriter('output.mp4', fourcc, FPS, videodims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fidx, f in enumerate(data):\n",
    "    print( f'Done: {round(fidx * 100 / len(data), 1)} % - {f}', end=\"\\r\")\n",
    "    img = Image.open(f)\n",
    "    video.write(cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR))\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COgVideoX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import CogVideoXImageToVideoPipeline\n",
    "from diffusers.utils import export_to_video, load_image\n",
    "\n",
    "prompt = \"The man is holding a helmet in his left hand and raising his right arm.\"\n",
    "image = img.copy()\n",
    "pipe = CogVideoXImageToVideoPipeline.from_pretrained(\n",
    "    \"THUDM/CogVideoX-5b-I2V\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.vae.enable_tiling()\n",
    "pipe.vae.enable_slicing()\n",
    "\n",
    "video = pipe(\n",
    "    prompt=prompt,\n",
    "    image=image,\n",
    "    num_videos_per_prompt=1,\n",
    "    num_inference_steps=50,\n",
    "    num_frames=49,\n",
    "    guidance_scale=6,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    ").frames[0]\n",
    "\n",
    "export_to_video(video, \"output.mp4\", fps=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 ('stt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9295a5f9b6a51b8fce19d82aba4e4c52d6c61c4eff47599c9d114980109943e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
